version: "2.2"
services:
#sql-client 没有采用第三方镜像，而是借助 docker compose 的 编译能力
  sql-client:
    image: flink-sql-client-env:0.1
    depends_on:
      - jobmanager
      - kafka
      - elasticsearch
    environment:
      FLINK_JOBMANAGER_HOST: jobmanager
      ZOOKEEPER_CONNECT: zookeeper
      KAFKA_BOOTSTRAP: kafka
      MYSQL_HOST: mysql
      ES_HOST: elasticsearch
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  jobmanager:
    image: flink:1.11.1-scala_2.11
    ports:
      - 8081:8081
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager

  taskmanager:
    image: flink:1.11.1-scala_2.11
    depends_on:
      - jobmanager
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 4
  
  mysql:
    image: mysql:5.7
    container_name: mysql
    command: 
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
      --lower-case-table-names=1  # 忽略数据表名称的大小写
    restart: always # 跟随 docker 的启动而启动
    environment:
      MYSQL_ROOT_PASSWORD: 123456
    ports:
      - 3306:3306
    volumes:
      - ~/docker_compose/mysql5.7/data/db:/var/lib/mysql  # 数据文件挂载
      - ~/docker_compose/mysql5.7/data/conf:/etc/mysql/conf.d
      - ~/docker_compose/mysql5.7/log:/var/log/mysql


# ZK 的 image 就复用 fraud 的 docker compose 中的 3.4.9
  zookeeper:
    image: 'zookeeper:3.4.9'
    restart: unless-stopped
    hostname: zookeeper
    ports:
    - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper:2888:3888  
  
# 本次 Kafka 镜像选用 wurstmeister的 wurstmeister/kafka:2.12-2.2.1 而部分是 confluence 的，原因在于 confluence 的更加官方
# 而 wurstmeister 维护的 kafka 镜像则是更加轻量级，有助于个人调试环境
  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
      - "9094:9094"
    depends_on:
      - zookeeper
    environment:
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://:9094,OUTSIDE://locaohost:9092
      - KAFKA_LISTENERS=INSIDE://:9094,OUTSIDE://:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CREATE_TOPICS="user_behavior:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
# ES 配置
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
#Elasticsearch does some bootstrap checks on startup. If you want to start it as a single node in Docker,
#you need to disable these, or it will not open the TCP/IP port.
      - discovery.type=single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536

# kibana 配置
  kibana:
    image: docker.elastic.co/kibana/kibana:7.6.0
    ports:
      - "5601:5601"
    

    
  

# docker compose 要求上面用到的 volumes 要在下面注册
# volumes:
#   var:
#     run:
#       docker.sock